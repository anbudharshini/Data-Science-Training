{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Module 1: Setup & SparkSession Initialization\n",
        "##Tasks:\n",
        "##Install and configure PySpark in your local system or Colab.\n",
        "##Initialize Spark with:"
      ],
      "metadata": {
        "id": "pMlRDt8Gfpiq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hwHZ7fHLfXEE"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"BotCampus PySpark Practice\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create a DataFrame from:"
      ],
      "metadata": {
        "id": "sqmRDpXsgQRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (\"Anjali\", \"Bangalore\", 24),\n",
        "    (\"Ravi\", \"Hyderabad\", 28),\n",
        "    (\"Kavya\", \"Delhi\", 22),\n",
        "    (\"Meena\", \"Chennai\", 25),\n",
        "    (\"Arjun\", \"Mumbai\", 30)\n",
        "]\n",
        "columns = [\"name\", \"city\", \"age\"]\n",
        "df = spark.createDataFrame(data, columns)"
      ],
      "metadata": {
        "id": "UyStMKRZgSl7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Show schema, explain data types, and convert to RDD."
      ],
      "metadata": {
        "id": "ouUCNW30gg9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show schema\n",
        "df.printSchema()\n",
        "df.show()\n",
        "\n",
        "# Convert to RDD\n",
        "rdd = df.rdd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XawAoyDOgqUC",
        "outputId": "8d067ddf-860d-4db5-85b2-00e62a9f019b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- age: long (nullable = true)\n",
            "\n",
            "+------+---------+---+\n",
            "|  name|     city|age|\n",
            "+------+---------+---+\n",
            "|Anjali|Bangalore| 24|\n",
            "|  Ravi|Hyderabad| 28|\n",
            "| Kavya|    Delhi| 22|\n",
            "| Meena|  Chennai| 25|\n",
            "| Arjun|   Mumbai| 30|\n",
            "+------+---------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print .collect() and df.rdd.map() output."
      ],
      "metadata": {
        "id": "Kz-qDrcZgzRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"RDD .collect():\", rdd.collect())\n",
        "print(\"RDD .map():\", rdd.map(lambda x: (x.name, x.age)).collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9SfD3peg3wN",
        "outputId": "e0b16559-9cec-442f-cc07-ac87e0abe02a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RDD .collect(): [Row(name='Anjali', city='Bangalore', age=24), Row(name='Ravi', city='Hyderabad', age=28), Row(name='Kavya', city='Delhi', age=22), Row(name='Meena', city='Chennai', age=25), Row(name='Arjun', city='Mumbai', age=30)]\n",
            "RDD .map(): [('Anjali', 24), ('Ravi', 28), ('Kavya', 22), ('Meena', 25), ('Arjun', 30)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module 2: RDDs & Transformations\n",
        "##Scenario: You received app feedback from users in free-text"
      ],
      "metadata": {
        "id": "Hyj1-jTXg8jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feedback = spark.sparkContext.parallelize([\n",
        "    \"Ravi from Bangalore loved the delivery\",\n",
        "    \"Meena from Hyderabad had a late order\",\n",
        "    \"Ajay from Pune liked the service\",\n",
        "    \"Anjali from Delhi faced UI issues\",\n",
        "    \"Rohit from Mumbai gave positive feedback\"\n",
        "])"
      ],
      "metadata": {
        "id": "CFIPRMFIhDiW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tasks:\n",
        "##Split each line into words (flatMap )."
      ],
      "metadata": {
        "id": "EqCmc2qjhID3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_rdd = feedback.flatMap(lambda line: line.split())"
      ],
      "metadata": {
        "id": "3JsdkB8fhR0w"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove stop words (from , the , etc.)."
      ],
      "metadata": {
        "id": "4WSWSTf9h0qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop words list\n",
        "stop_words = {\"from\", \"the\", \"a\", \"had\", \"with\", \"and\", \"an\", \"of\", \"to\"}\n",
        "# Clean & transform\n",
        "words = feedback.flatMap(lambda line: line.lower().split()) \\\n",
        ".filter(lambda word: word not in stop_words)"
      ],
      "metadata": {
        "id": "r8H46Hy_h6IO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Count each word frequency using reduceByKey"
      ],
      "metadata": {
        "id": "HtKuHm0EiGkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_count = words.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)"
      ],
      "metadata": {
        "id": "qq-VSY-DiSBN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Find top 3 most frequent non-stop words."
      ],
      "metadata": {
        "id": "fwR1220aiU9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_3 = word_count.takeOrdered(3, key=lambda x: -x[1])\n",
        "print(\"Top 3 frequent words:\", top_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfXhDZb5ic-G",
        "outputId": "f6552f1f-7eea-4d02-de83-8dfebab00574"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 frequent words: [('loved', 1), ('liked', 1), ('service', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Module 3: DataFrames & Transformation (With Joins)\n",
        "##DataFrames"
      ],
      "metadata": {
        "id": "-Lv_BAH-ikWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, when\n",
        "students = [\n",
        "    (\"Amit\", \"10-A\", 89),\n",
        "    (\"Kavya\", \"10-B\", 92),\n",
        "    (\"Anjali\", \"10-A\", 78),\n",
        "    (\"Rohit\", \"10-B\", 85),\n",
        "    (\"Sneha\", \"10-C\", 80)\n",
        "]\n",
        "attendance = [\n",
        "    (\"Amit\", 24),\n",
        "    (\"Kavya\", 22),\n",
        "    (\"Anjali\", 20),\n",
        "    (\"Rohit\", 25),\n",
        "    (\"Sneha\", 19)\n",
        "]\n",
        "df_students = spark.createDataFrame(students, [\"name\", \"section\", \"marks\"])\n",
        "df_attendance = spark.createDataFrame(attendance, [\"name\", \"days_present\"])"
      ],
      "metadata": {
        "id": "0olH56Zlitfr"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tasks:\n",
        "##Join both DataFrames on name ."
      ],
      "metadata": {
        "id": "ix4c7F_QjEcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_joined = df_students.join(df_attendance, on=\"name\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tknRgFHNjKrW",
        "outputId": "f7878a21-b4ce-4390-d5d6-2c114803fabf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+------------+\n",
            "|  name|section|marks|days_present|\n",
            "+------+-------+-----+------------+\n",
            "|  Amit|   10-A|   89|          24|\n",
            "|Anjali|   10-A|   78|          20|\n",
            "| Kavya|   10-B|   92|          22|\n",
            "| Rohit|   10-B|   85|          25|\n",
            "| Sneha|   10-C|   80|          19|\n",
            "+------+-------+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a new column: attendance_rate = days_present / 25 ."
      ],
      "metadata": {
        "id": "Db60Q9k-jPBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_joined = df_joined.withColumn(\"attendance_rate\", col(\"days_present\") / 25)"
      ],
      "metadata": {
        "id": "K_rS3gwJjS-L"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grade students using\n",
        "when :\n",
        " A: >90, B: 80–90, C: <80."
      ],
      "metadata": {
        "id": "cFt3E6vCjfWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, when\n",
        "df_joined = df_students.join(df_attendance, on=\"name\", how=\"inner\")\n",
        "df_joined = df_joined.withColumn(\"grade\",when(col(\"marks\") > 90, \"A\").when(col(\"marks\") >= 80, \"B\").otherwise(\"C\"))\n",
        "df_joined.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKZY5CqCjkA9",
        "outputId": "043f8bf7-4181-4f8e-8c92-9805b2309ec6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+------------+-----+\n",
            "|  name|section|marks|days_present|grade|\n",
            "+------+-------+-----+------------+-----+\n",
            "|  Amit|   10-A|   89|          24|    B|\n",
            "|Anjali|   10-A|   78|          20|    C|\n",
            "| Kavya|   10-B|   92|          22|    A|\n",
            "| Rohit|   10-B|   85|          25|    B|\n",
            "| Sneha|   10-C|   80|          19|    B|\n",
            "+------+-------+-----+------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter students with good grades but poor attendance (<80%)."
      ],
      "metadata": {
        "id": "ZumhsH6BmvfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add attendance_rate column\n",
        "df_joined = df_joined.withColumn(\"attendance_rate\", col(\"days_present\") / 30)\n",
        "\n",
        "# Filter based on grade and attendance_rate\n",
        "df_filtered = df_joined.filter((col(\"grade\").isin(\"A\", \"B\")) & (col(\"attendance_rate\") < 0.8))\n",
        "df_filtered.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KBmYtDRmy6s",
        "outputId": "868bc0f7-d018-4e9c-8b9d-c6ea8cfc32e2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+-----+------------+-----+------------------+\n",
            "| name|section|marks|days_present|grade|   attendance_rate|\n",
            "+-----+-------+-----+------------+-----+------------------+\n",
            "|Kavya|   10-B|   92|          22|    A|0.7333333333333333|\n",
            "|Sneha|   10-C|   80|          19|    B|0.6333333333333333|\n",
            "+-----+-------+-----+------------+-----+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module 4: Ingest CSV & JSON, Save to Parquet\n",
        "## Tasks:\n"
      ],
      "metadata": {
        "id": "RBJQ7OsZoCH3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Read both formats into DataFrames.\n"
      ],
      "metadata": {
        "id": "_L7ogd1KpAGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, explode\n",
        "spark = SparkSession.builder.appName(\"SingleNestedJson\").getOrCreate()\n",
        "data = [{\n",
        "    \"id\": 201,\n",
        "    \"name\": \"Nandini\",\n",
        "    \"contact\": {\n",
        "        \"email\": \"nandi@example.com\",\n",
        "        \"city\": \"Hyderabad\"\n",
        "    },\n",
        "    \"skills\": [\"Python\", \"Spark\", \"SQL\"]\n",
        "}]\n",
        "\n",
        "rdd = spark.sparkContext.parallelize(data)\n",
        "df_json = spark.read.json(rdd)\n",
        "df_json.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDXJO02vqioY",
        "outputId": "d03e1033-9dbe-4eec-8255-abda51e4254a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- contact: struct (nullable = true)\n",
            " |    |-- city: string (nullable = true)\n",
            " |    |-- email: string (nullable = true)\n",
            " |-- id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- skills: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Flatten nested JSON using select , col , alias , explode ."
      ],
      "metadata": {
        "id": "C2wbUjxfq8Sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_flat = df_json.select(\n",
        "    col(\"id\"),\n",
        "    col(\"name\"),\n",
        "    col(\"contact.email\").alias(\"email\"),\n",
        "    col(\"contact.city\").alias(\"city\"),\n",
        "    explode(col(\"skills\")).alias(\"skill\")\n",
        ")"
      ],
      "metadata": {
        "id": "zuCE--M9qk8C"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Save both as Parquet files partitioned by city."
      ],
      "metadata": {
        "id": "pVz8VdVOq9jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_csv.write.mode(\"overwrite\").partitionBy(\"city\").parquet(\"/tmp/csv_output\")\n",
        "df_flat.write.mode(\"overwrite\").partitionBy(\"city\").parquet(\"/tmp/json_output\")"
      ],
      "metadata": {
        "id": "nkLtVF7NrAMR"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/csv_output.zip /tmp/csv_output\n",
        "!zip -r /content/json_output.zip /tmp/json_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzrejDMwrPmX",
        "outputId": "75882edd-ba76-47f9-9348-4796bd12547b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: tmp/csv_output/ (stored 0%)\n",
            "  adding: tmp/csv_output/._SUCCESS.crc (stored 0%)\n",
            "  adding: tmp/csv_output/city=Mumbai/ (stored 0%)\n",
            "  adding: tmp/csv_output/city=Mumbai/.part-00000-78f9ca8a-b660-415f-9b43-e0144575585a.c000.snappy.parquet.crc (stored 0%)\n",
            "  adding: tmp/csv_output/city=Mumbai/part-00000-78f9ca8a-b660-415f-9b43-e0144575585a.c000.snappy.parquet (deflated 47%)\n",
            "  adding: tmp/csv_output/city=Bangalore/ (stored 0%)\n",
            "  adding: tmp/csv_output/city=Bangalore/.part-00000-78f9ca8a-b660-415f-9b43-e0144575585a.c000.snappy.parquet.crc (stored 0%)\n",
            "  adding: tmp/csv_output/city=Bangalore/part-00000-78f9ca8a-b660-415f-9b43-e0144575585a.c000.snappy.parquet (deflated 48%)\n",
            "  adding: tmp/csv_output/_SUCCESS (stored 0%)\n",
            "  adding: tmp/csv_output/city=Chennai/ (stored 0%)\n",
            "  adding: tmp/csv_output/city=Chennai/.part-00000-78f9ca8a-b660-415f-9b43-e0144575585a.c000.snappy.parquet.crc (stored 0%)\n",
            "  adding: tmp/csv_output/city=Chennai/part-00000-78f9ca8a-b660-415f-9b43-e0144575585a.c000.snappy.parquet (deflated 48%)\n",
            "  adding: tmp/json_output/ (stored 0%)\n",
            "  adding: tmp/json_output/._SUCCESS.crc (stored 0%)\n",
            "  adding: tmp/json_output/_SUCCESS (stored 0%)\n",
            "  adding: tmp/json_output/city=Hyderabad/ (stored 0%)\n",
            "  adding: tmp/json_output/city=Hyderabad/.part-00001-a0468b25-5b98-4325-ae01-6524fcfe1979.c000.snappy.parquet.crc (stored 0%)\n",
            "  adding: tmp/json_output/city=Hyderabad/part-00001-a0468b25-5b98-4325-ae01-6524fcfe1979.c000.snappy.parquet (deflated 51%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/csv_output.zip\")\n",
        "files.download(\"/content/json_output.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "bH26Wp3TrROM",
        "outputId": "29b66b25-29e4-4949-e19f-3a6e6ba9734f"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0609da88-d270-4364-b863-d2ca92958d0b\", \"csv_output.zip\", 4980)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_247507d4-724b-44e5-a81c-1a9f64429d3a\", \"json_output.zip\", 2107)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module 5: Spark SQL with Temp Views\n",
        " Tasks:\n",
        " Register the students DataFrame as students_view .\n",
        " Write and run the following queries:"
      ],
      "metadata": {
        "id": "yCfPoPfDriNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Register view\n",
        "df_students.createOrReplaceTempView(\"students_view\")\n",
        "\n",
        "# a) Average marks per section\n",
        "spark.sql(\"\"\"select section, AVG(marks) as avg_marks\n",
        "from students_view\n",
        "group by section\"\"\").show()\n",
        "\n",
        "# b) Top scorer per section\n",
        "spark.sql(\"\"\"select section, name, marks from(\n",
        "select *, rank() over(partition by section order by marks desc) as rnk\n",
        "from students_view\n",
        ")where rnk = 1\"\"\").show()\n",
        "\n",
        "# c) Count by grade\n",
        "df_students = df_students.withColumn(\"grade\", when(col(\"marks\") > 90, \"A\").when((col(\"marks\") >= 80), \"B\").otherwise(\"C\"))\n",
        "df_students.createOrReplaceTempView(\"graded_students\")\n",
        "\n",
        "spark.sql(\"select grade, count(*) as count from graded_students group by grade\").show()\n",
        "\n",
        "# d) Above class average\n",
        "spark.sql(\"\"\"\n",
        "select * from students_view\n",
        "where marks > (select avg(marks) from students_view)\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bqx64C-ArrJQ",
        "outputId": "ab2d196a-2cec-414a-d10f-c7b156c517bb"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+\n",
            "|section|avg_marks|\n",
            "+-------+---------+\n",
            "|   10-A|     83.5|\n",
            "|   10-B|     88.5|\n",
            "|   10-C|     80.0|\n",
            "+-------+---------+\n",
            "\n",
            "+-------+-----+-----+\n",
            "|section| name|marks|\n",
            "+-------+-----+-----+\n",
            "|   10-A| Amit|   89|\n",
            "|   10-B|Kavya|   92|\n",
            "|   10-C|Sneha|   80|\n",
            "+-------+-----+-----+\n",
            "\n",
            "+-----+-----+\n",
            "|grade|count|\n",
            "+-----+-----+\n",
            "|    B|    3|\n",
            "|    A|    1|\n",
            "|    C|    1|\n",
            "+-----+-----+\n",
            "\n",
            "+-----+-------+-----+\n",
            "| name|section|marks|\n",
            "+-----+-------+-----+\n",
            "| Amit|   10-A|   89|\n",
            "|Kavya|   10-B|   92|\n",
            "|Rohit|   10-B|   85|\n",
            "+-----+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Module 6: Partitioned Data & Incremental Loading\n",
        "##Step 1: Full Load"
      ],
      "metadata": {
        "id": "_gBp5kCnsrAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_students.write.mode(\"overwrite\").partitionBy(\"section\").parquet(\"output/students/\")"
      ],
      "metadata": {
        "id": "PnC-9jqvsw7t"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Incremental Load"
      ],
      "metadata": {
        "id": "2SsgUToss0jo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "incremental = [(\"Tejas\", \"10-A\", 91)]\n",
        "df_inc = spark.createDataFrame(incremental, [\"name\", \"section\", \"marks\"])\n",
        "df_inc.write.mode(\"append\").partitionBy(\"section\").parquet(\"output/students/\")"
      ],
      "metadata": {
        "id": "Ev9RD_Ces3jJ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tasks:\n",
        "##List files in output/students/ using Python."
      ],
      "metadata": {
        "id": "sQU2vgFgs7XC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"Files in 10-A partition:\")\n",
        "print(os.listdir(\"output/students/section=10-A\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMs9F5j5tAj2",
        "outputId": "07fd3b7d-b772-4906-fb63-b00b28e5792c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in 10-A partition:\n",
            "['.part-00001-6ff44c48-396d-458d-a041-8c0e9f36ac8b.c000.snappy.parquet.crc', '.part-00001-15ca460b-716b-41a1-9dbe-26fcfcecca6c.c000.snappy.parquet.crc', '.part-00000-e400fb43-5442-4a5a-af18-e4808e060233.c000.snappy.parquet.crc', 'part-00001-e400fb43-5442-4a5a-af18-e4808e060233.c000.snappy.parquet', 'part-00001-15ca460b-716b-41a1-9dbe-26fcfcecca6c.c000.snappy.parquet', '.part-00001-e400fb43-5442-4a5a-af18-e4808e060233.c000.snappy.parquet.crc', 'part-00000-e400fb43-5442-4a5a-af18-e4808e060233.c000.snappy.parquet', 'part-00001-6ff44c48-396d-458d-a041-8c0e9f36ac8b.c000.snappy.parquet']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read only partition 10-A and list students.\n",
        "## Compare before/after counts for section 10-A ."
      ],
      "metadata": {
        "id": "XncaYNzWtfGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_10a = spark.read.parquet(\"output/students/section=10-A\")\n",
        "df_10a.show()\n",
        "print(\"Total in 10-A:\", df_10a.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTt9zTIktnIB",
        "outputId": "4d1181d1-9e2d-409f-9d40-aaa2f921b8b9"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-----+\n",
            "|  name|marks|grade|\n",
            "+------+-----+-----+\n",
            "|Anjali|   78|    C|\n",
            "|  Amit|   89|    B|\n",
            "| Tejas|   91| NULL|\n",
            "| Tejas|   91| NULL|\n",
            "+------+-----+-----+\n",
            "\n",
            "Total in 10-A: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Module 7: ETL Pipeline – End to End"
      ],
      "metadata": {
        "id": "m2GM4-00uBYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "WVMZakmduCbU",
        "outputId": "3931b134-8be2-4d9d-8d68-643f94102a72"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-507dbb27-f702-4ff2-853f-f4ccd8282d85\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-507dbb27-f702-4ff2-853f-f4ccd8282d85\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving raw_emp.csv to raw_emp.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, when\n",
        "\n",
        "# Fix column name by trimming whitespace\n",
        "df_trimmed = df_raw.withColumnRenamed(\"bonus \", \"bonus\")\n",
        "\n",
        "# Clean: Fill missing bonus\n",
        "df_filled = df_trimmed.withColumn(\"bonus\", when(col(\"bonus\").isNull(), 2000).otherwise(col(\"bonus\")))\n",
        "\n",
        "# CTC\n",
        "df_ctc = df_filled.withColumn(\"total_ctc\", col(\"salary\") + col(\"bonus\"))\n",
        "\n",
        "# Filter\n",
        "df_filtered = df_ctc.filter(col(\"total_ctc\") > 65000)\n",
        "\n",
        "# Save as JSON and Parquet\n",
        "df_filtered.write.mode(\"overwrite\").json(\"/tmp/final_json_output\")\n",
        "df_filtered.write.mode(\"overwrite\").partitionBy(\"dept\").parquet(\"/tmp/final_parquet_output\")"
      ],
      "metadata": {
        "id": "qMboXZUaukta"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /tmp/final_json_output.zip /tmp/final_json_output\n",
        "!zip -r /tmp/final_parquet_output.zip /tmp/final_parquet_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e90rSwvJv__j",
        "outputId": "f1a7b197-a3df-4fdf-efc9-2674623ac42f"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: tmp/final_json_output/ (stored 0%)\n",
            "  adding: tmp/final_json_output/._SUCCESS.crc (stored 0%)\n",
            "  adding: tmp/final_json_output/part-00000-d1a04de6-bd75-4029-8ea7-44ec8009d9a5-c000.json (deflated 36%)\n",
            "  adding: tmp/final_json_output/_SUCCESS (stored 0%)\n",
            "  adding: tmp/final_json_output/.part-00000-d1a04de6-bd75-4029-8ea7-44ec8009d9a5-c000.json.crc (stored 0%)\n",
            "  adding: tmp/final_parquet_output/ (stored 0%)\n",
            "  adding: tmp/final_parquet_output/._SUCCESS.crc (stored 0%)\n",
            "  adding: tmp/final_parquet_output/dept=IT/ (stored 0%)\n",
            "  adding: tmp/final_parquet_output/dept=IT/.part-00000-07b29636-c8f3-42d3-b409-c1939b4414ea.c000.snappy.parquet.crc (stored 0%)\n",
            "  adding: tmp/final_parquet_output/dept=IT/part-00000-07b29636-c8f3-42d3-b409-c1939b4414ea.c000.snappy.parquet (deflated 52%)\n",
            "  adding: tmp/final_parquet_output/_SUCCESS (stored 0%)\n",
            "  adding: tmp/final_parquet_output/dept=Finance/ (stored 0%)\n",
            "  adding: tmp/final_parquet_output/dept=Finance/.part-00000-07b29636-c8f3-42d3-b409-c1939b4414ea.c000.snappy.parquet.crc (stored 0%)\n",
            "  adding: tmp/final_parquet_output/dept=Finance/part-00000-07b29636-c8f3-42d3-b409-c1939b4414ea.c000.snappy.parquet (deflated 52%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/tmp/final_json_output.zip\")\n",
        "files.download(\"/tmp/final_parquet_output.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "KTWF8XZnwBQb",
        "outputId": "80be2b4e-77dc-47d9-e483-7182b5515ac1"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c9dd4c58-e50c-497e-8821-1332851c91b7\", \"final_json_output.zip\", 1301)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_647a5430-bfed-42b1-87f4-4a800080d7e5\", \"final_parquet_output.zip\", 3776)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}